{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michalis0/Business-Intelligence-and-Analytics/blob/master/8%20-%20Regression2/Exercises/Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-TQK8ILyUmK"
      },
      "source": [
        "# Exercise: Multivariate Linear Regression, Overfitting and Crossvalidation\n",
        "\n",
        "This exercise is an application of what you learned in the walkthrough. The following cell gathers the different modules you need for this exercise (take a look at the sklearn library).\n",
        "\n",
        "Some exercises consist of filling a part of the code without writing the whole code. Replace the `\"YOUR CODE HERE\"` by your own code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVMlZ-Um_pE6"
      },
      "source": [
        "# Useful starting lines\n",
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#from matplotlib import collections  as mc\n",
        "import pandas as pd \n",
        "\n",
        "# Sklearn import\n",
        "from sklearn.preprocessing import MinMaxScaler # Normalization\n",
        "from sklearn.linear_model import LinearRegression # Regression linear model\n",
        "from sklearn.model_selection import train_test_split # Splitting the data set\n",
        "from sklearn.preprocessing import LabelEncoder #1-hot encoding\n",
        "from sklearn.preprocessing import OneHotEncoder # Label encoding\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score # Metrics for errors\n",
        "from sklearn.model_selection import KFold # Cross validation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoSlMRWc_uz5"
      },
      "source": [
        "##Loading the dataset\n",
        "This week, we are going to use the `audi` dataset. Our task is to figure out how the different features have an influence the price of a car.\n",
        "Load the pandas dataset from the given URL. Then display the first 5 rows. How many observations and columns do we have? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRApH5rg_yls",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "c658f221-21d9-488b-9d2b-0c1acf5883e1"
      },
      "source": [
        "url = 'https://media.githubusercontent.com/media/michalis0/Business-Intelligence-and-Analytics/master/data/audi.csv'\n",
        "# Load the data\n",
        "audi = \"YOUR CODE HERE\"\n",
        "display(\"YOUR CODE HERE\")\n",
        "\n",
        "# Observations and columns (dimensions)\n",
        "print(\"Number of observations\", \"YOUR CODE HERE\")\n",
        "print(\"Number of dimensions\", \"YOUR CODE HERE\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'YOUR CODE HERE'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Number of observations YOUR CODE HERE\n",
            "Number of dimensions YOUR CODE HERE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-d5NsjRARWk"
      },
      "source": [
        "An overview of the columns:\n",
        " * `price`: price in Â£\n",
        " * `model` : audi model\n",
        " * `year`: registration year\n",
        " * `transmission`: type of gearbox\n",
        " * `mileage`: distance used\n",
        " * `fuelType`: engine fuel\n",
        " * `tax` : road tax\n",
        " * `mpg`: miles per gallon\n",
        " * `engineSize`: size in litres\n",
        " \n",
        " We will try to predict the price using some of the other variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcb2zBloAVmY"
      },
      "source": [
        "\n",
        "##Dealing with categorical variables\n",
        "First we have to deal with our categorical variables. Since it's not possible to regress anything on them, we must transform them using techniques such as label encoding or 1-hot encoding. In this part, our goal is to obtain a final dataset :`AUDI` where there is no categorical variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdZLbIjHAXNE"
      },
      "source": [
        "Let's start with the `fuelType`. Since there are only 3 types of engine fuel, try to assign 0 for 'Petrol', 1 for 'Diesel' and 2 for 'Hybrid'. \n",
        "\n",
        "**hint :** use .replace()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWejYDJFAgL_"
      },
      "source": [
        "audi[\"YOUR CODE HERE\"] = \"YOUR CODE HERE\"\n",
        "display(audi.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lom3z3AmAvjJ"
      },
      "source": [
        "Now, let's transform `model`. There are a lot of various models, thinking about what you've seen in last week lesson which technique should we use ?\n",
        "\n",
        "**hint :**   Here we want to encode for a specific column. Do not forget to use fit_transform()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZrSyds0AwmT"
      },
      "source": [
        "#Label encoding \n",
        "X = \"YOUR CODE HERE\"\n",
        "\n",
        "X_label = \"YOUR CODE HERE\"\n",
        "\n",
        "#we drop the initial model column\n",
        "del audi['model']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MSlY-JaBvxB"
      },
      "source": [
        "Last of all, let's tackle `transmission` using 1-hot encoding.\n",
        "\n",
        "**hint :** create a data frame with dummy variables then concatenate it with the initial dataset using pd.concat()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQa7zrDaCBo2"
      },
      "source": [
        "#We create a DF with Dummy variables\n",
        "dummies = \"YOUR CODE HERE\"\n",
        "X_hot = \"YOUR CODE HERE\"\n",
        "\n",
        "#We drop the transmission column \n",
        "del X_hot[\"transmission\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fhD1mc8Cbfl"
      },
      "source": [
        "Once it is done, the last thing to do is to concatenate the X_hot and the X_label dataset.\n",
        "**hint** : use the pd.concat() fuction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgODY7hhCrwV"
      },
      "source": [
        "AUDI = \"YOUR CODE HERE\"\n",
        "display(AUDI.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIYvDXeMCwkl"
      },
      "source": [
        "## Multivariate Regression\n",
        "Now that our variables are usable  let's get to regression. Follow the steps covered last week and try to predict the `price` using our variables. Use your new dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maH3dPcnDXEc"
      },
      "source": [
        "#We want to predict the price using other columns\n",
        "y = \"YOUR CODE HERE\"\n",
        "X = \"YOUR CODE HERE\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG0H4WjYDY1p"
      },
      "source": [
        "#Split the data set\n",
        "X_train, X_test, y_train, y_test = \"YOUR CODE HERE\"\n",
        "\n",
        "#Create and fit the model\n",
        "model = \"YOUR CODE HERE\"\n",
        "\"YOUR CODE HERE\"\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Performance metrics\n",
        "print(\"Test scores: \")\n",
        "print(\"MAE %.2f\" % \"YOUR CODE HERE\")\n",
        "print(\"MSE %.2f\" % \"YOUR CODE HERE\")\n",
        "print(\"R^2 %.2f\" % \"YOUR CODE HERE\")\n",
        "\n",
        "print(\"Train metrics\")\n",
        "print(\"params: \", \"YOUR CODE HERE\")\n",
        "print(\"constant: \", \"YOUR CODE HERE\")\n",
        "print(\"R^2 score: \", \"YOUR CODE HERE\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrZWmQnqTfaL"
      },
      "source": [
        "## Overfitting and Cross Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kODpgFvRIFs"
      },
      "source": [
        "### Overfitting\n",
        "First, compute the mean absolute error of the training set and the testing set, save the values into the two arrays which are already defined. Plot the different errors values depending on the number of features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-LJZVsQRMeb"
      },
      "source": [
        "# Arrays to save the different errors\n",
        "train_err = []\n",
        "test_err = []\n",
        "\n",
        "# Iterate over our features\n",
        "for nbr_col in range(1, 13):\n",
        "    # Select the good number of features for X\n",
        "    X_temp = X[X.columns[:nbr_col]]\n",
        "    # Split the dat set\n",
        "    X_train, X_test, y_train, y_test = \"YOUR CODE HERE\"\n",
        "    # Create the linear model\n",
        "    LR = \"YOUR CODE HERE\"\n",
        "    # Fit the linear model\n",
        "   \"YOUR CODE HERE\"\n",
        "\n",
        "    #Compute and save the mean absolute error fro training and testing set\n",
        "    train_err.append(\"YOUR CODE HERE\")\n",
        "    test_err.append(\"YOUR CODE HERE\")\n",
        "\n",
        "# Print the train and the test errors\n",
        "print(\"Train error: \", train_err)\n",
        "print(\"Test error : \", test_err)\n",
        "\n",
        "plt.title(\"Training and test error regarding the number of features\")\n",
        "plt.plot(range(1,13), train_err, label=\"train_error\")\n",
        "plt.plot(range(1,13), test_err, label=\"test_error\")\n",
        "plt.legend(fontsize=10)\n",
        "plt.xlabel(\"Number of features\")\n",
        "plt.ylabel(\"Error\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbdSnp5pSvWc"
      },
      "source": [
        "###Cross validation\n",
        "The standard way to do a hyperparameter tuning is through cross validation. We need to make sure that our model has a has a good generalisation power and performs well on unseen data. We use the KFold sklearn module to separate the data set into different combination of data. It will reduce the overfitting issue. When you create a new KFold object, you have to specify the number of splits you want."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxXTpMa0Rpus"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "y = \"YOUR CODE HERE\"\n",
        "X = \"YOUR CODE HERE\"\n",
        "\n",
        "#Initialize the kfold with 10 splits\n",
        "kf = \"YOUR CODE HERE\"\n",
        "\n",
        "#Define the linear model\n",
        "model = \"YOUR CODE HERE\"\n",
        "\n",
        "#Create array to save the scores\n",
        "mae_cumm = []\n",
        "mse_cumm = []\n",
        "r2_cumm = []\n",
        "\n",
        "#Iterate over the different split (use the split() function)\n",
        "for train_index, test_index in kf.split(X):\n",
        "  #Split the data set\n",
        "  X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
        "  y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "  #Fit the model\n",
        "  \"YOUR CODE HERE\"\n",
        "  \n",
        "  predictions = model.predict(X_test)\n",
        "\n",
        "  mae_cumm.append(mean_absolute_error(y_test, predictions))\n",
        "  mse_cumm.append(mean_squared_error(y_test, predictions))\n",
        "  r2_cumm.append(r2_score(y_test, predictions))\n",
        "\n",
        "  \n",
        "mean_mae = sum(mae_cumm)/len(mae_cumm)\n",
        "mean_mse = sum(mse_cumm)/len(mse_cumm)\n",
        "mean_r2 = sum(r2_cumm)/len(r2_cumm)\n",
        "\n",
        "print(\"The mean absolute error of all our folds was: \",round(mean_mae, 3))\n",
        "print(\"The mean squared error of all our folds was: \", round(mean_mse, 3))\n",
        "print(\"The mean accuracy of all our folds was: \", round(mean_r2, 3))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
